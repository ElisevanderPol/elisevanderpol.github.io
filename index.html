<!doctype html>
<html lang="">

<head>
	<title>Elise van der Pol </title>
</head>

<!-- Style adapted from txti.es/ -->
<style type="text/css">body {font-size: 18px; line-height: 1.6em; max-width: 80em; margin: auto; padding: 0 2%; color: #444;} img {max-width: 100%; display: block; margin: .75em auto;} </style>

<body>
	<div>
		<!--<img align="right" src="assets/twitter_foto.jpg" alt="Picture of Elise van der Pol in front of a whiteboard" width="256">-->
		<img align="right" src="assets/new_photo.jpg" alt="Picture of Elise van der Pol flexing a bicep" width="384">
		<h1>Elise van der Pol</h1>
		<h3>PhD student, University of Amsterdam</h3>
	</div>
	<div>
		<ul>
			<li>
				E-mail: e.e.vanderpol[at]uva[dot]nl
			</li>
			<li>
				<a href="https://twitter.com/ElisevanderPol">Twitter</a>
			</li>
			<li>
				<a href="https://scholar.google.nl/citations?hl=en&user=564o-vIAAAAJ">Google Scholar</a>
			</li>
		</ul>
	</div>

	<div>
		<p>My research interests lie in structure, symmetry, and equivariance in reinforcement learning and machine learning. I'm a PhD student in the <a href="https://amlab.science.uva.nl">Amsterdam Machine Learning Lab</a>, working with <a href="https://staff.fnwi.uva.nl/m.welling/">Max Welling</a> (UvA), <a href="https://www.fransoliehoek.net/">Frans Oliehoek</a> (TU Delft) and <a href="https://staff.fnwi.uva.nl/h.c.vanhoof/homepage/">Herke van Hoof</a> (UvA). Before my PhD, I studied Artificial Intelligence at the University of Amsterdam where I obtained my Master's degree (cum laude). My MSc thesis was on the subject of <a href="papers/vanderpolTHESIS2016.pdf">Deep Reinforcement Learning for Coordinated Traffic Light Controllers</a>. I am also involved in <a href="https://uva-iai.github.io/">Inclusive AI</a>.</p>
	</div>

	<div>
		<h2>News</h2>
		<h4>2021</h4>
		<ul>
			<li><u>Paper</u>: New preprint: <a href="https://arxiv.org/abs/2110.04495">Multi-Agent MDP Homomorphic Networks</a>.</li>
			<li><u>Paper</u>: New preprint: <a href="https://arxiv.org/abs/2110.02905">Geometric and Physical Quantities improve E(3) Equivariant Message Passing</a>.</li>
			<li><u>Organization</u>: We're organizing a <a href="https://sites.google.com/view/ecorl2021/home">workshop on data-centric reinforcement learning</a> at NeurIPS 2021. </li>
			<li><u>Talk</u>: 15 July 2021 I gave a talk on <a href="https://www.youtube.com/watch?v=03MbWVlbefM">Geometric Deep Learning and Reinforcement Learning</a> for the <a href="https://geometricdeeplearning.com/lectures/">Geometric Deep Learning course</a> in the <a href="https://aimsammi.org/">African Masters in Machine Intelligence</a>.</li>
			<li><u>Paper</u>: <a href="https://arxiv.org/abs/2107.11676">The Impact of Negative Sampling on Contrastive Structured World Models</a> was accepted to the ICML 2021 workshop on <a href="https://icml21ssl.github.io/index.html">Self-Supervised Learning for Reasoning and Perception</a>.</li>
			<li><u>Visit</u>: I'm currently a research scientist intern in <a href="https://deepmind.com/">DeepMind</a>'s Multi-Agent team.</li>
			<li><u>Organization</u>: We organized an <a href="https://www.elisevanderpol.nl/badhypothesiscontest/">ICLR social</a> which took place 6 May 2021.</li>
			<li><u>Talk</u>: 7 May 2021 I gave a keynote talk on <b>Equivariance in MDPs</b> at the ICLR workshop on <a href="https://iclr.cc/virtual/2021/workshop/2126">Self-supervision for Reinforcement Learning</a>.</li>
		</ul>
		<h4>2020</h4>
		<ul>
			<li><u>Talk</u>: 15 December 2020 I gave a talk on <b>MDP Homomorphic Networks for Deep Reinforcement Learning</b> at the University of Tuebingen.</li>
			<li><u>Talk</u>: 23 November 2020 I gave a guest lecture <b>Introduction to Reinforcement Learning</b> in University of Amsterdam's MSc Data Science course <i>Applied Machine Learning</i>.</li>
			<li><u>Talk</u>: 13 November 2020 I gave a talk on <b>Equivariance, deep reinforcement learning, and making it work</b> at Leiden University.</li> 
			<li><u>Talk</u>: I gave a talk on <b>Data-efficient Reinforcement Learning</b> as part of TU Delft's <i><a href="https://courses.edx.org/courses/course-v1:DelftX+AIIP1x+3T2020/course/">AI in Practice</a></i> course.
			<li><u>Paper</u>: <b>MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning</b> was accepted to NeurIPS 2020.</li>
			<li><u>Paper</u>: <b>Plannable Approximations to MDP Homomorphisms: Equivariance under Actions</b> was accepted to AAMAS 2020.</li>
			<li><u>Paper</u>: <b>Contrastive Learning of Structured World Models</b> was accepted to ICLR 2020 as a long talk.</li>
		</ul>
		<h4>2019</h4>
		<ul><li><u>Paper</u>: <b>Hyperspherical Prototype Networks</b> was accepted to NeurIPS 2019.</li></ul>
	</div>

	<div>
		<h2>Publications and Preprints</h2>
		<h4>2021</h4>
		<ul>
			<li>Multi-Agent MDP Homomorphic Networks - <i> <b>E. van der Pol</b>, H. van Hoof, F.A. Oliehoek, M. Welling</i>, Arxiv preprint <br>
				&#183; <a href="https://arxiv.org/abs/2110.04495">PDF</a></li>
			<li>Geometric and Physical Quantities improve E(3) Equivariant Message Passing - <i> J. Brandstetter, R. Hesselink, <b>E. van der Pol</b>, E.J. Bekkers, M. Welling</i>, Arxiv preprint <br>
				&#183; <a href="https://arxiv.org/abs/2110.02905">PDF</a></li>
			<li>The Impact of Negative Sampling on Contrastive Structured World Models - <i>O. Biza, <b>E. van der Pol</b>, T. Kipf</i>, ICML 2021 workshop on Self-Supervised Learning for Reasoning and Perception<br> &#183; <a href="https://arxiv.org/pdf/2107.11676.pdf">PDF</a> &#183; <a href="https://github.com/ondrejba/negative-sampling-icml-21">Code</a> 
			</li>
		</ul>
		<h4>2020</h4>
		<ul>
			<li>
				MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning - <i> <b>E. van der Pol</b>, D.E. Worrall, H. van Hoof, F.A. Oliehoek, M. Welling</i>, NeurIPS 2020 <br>
				&#183; <a href="https://proceedings.neurips.cc/paper/2020/file/2be5f9c2e3620eb73c2972d7552b6cb5-Paper.pdf">PDF</a> &#183; <a href="mhn.html">Overview</a> &#183; <a href="https://videos.neurips.cc/search/mdp%20homomorphic/video/slideslive-38936788">Video</a> &#183; <a href="https://github.com/ElisevanderPol/mdp-homomorphic-networks">Code</a> &#183; <a href="https://proceedings.neurips.cc/paper/2020/file/2be5f9c2e3620eb73c2972d7552b6cb5-Supplemental.pdf">Supplementary</a>
			</li>
			<li>
				Plannable Approximations to MDP Homomorphisms: Equivariance under Actions - <i><b>E. van der Pol</b>, T. Kipf, F.A. Oliehoek, M. Welling</i>, AAMAS 2020  <br>
				&#183; <a href="https://arxiv.org/pdf/2002.11963.pdf">PDF</a> &#183; <a href="prae.html">Overview</a> &#183; <a href="https://underline.io/lecture/228-plannable-approximations-to-mdp-homomorphisms-equivariance-under-actions">Video</a> &#183; <a href="https://github.com/ElisevanderPol/PRAE">Code</a>
			</li>
			<li>
				Contrastive Learning of Structured World Models - <i>T. Kipf, <b>E. van der Pol</b>, M. Welling</i>, ICLR 2020 (Oral) <br>
				&#183; <a href="https://arxiv.org/pdf/1911.12247.pdf">PDF</a> &#183; <a href="https://iclr.cc/virtual/poster_H1gax6VtDB.html">Video</a> &#183; <a href="https://github.com/tkipf/c-swm">Code</a>
			</li>
		</ul>
		<h4>2019</h4>
		<ul>
			<li>
				Hyperspherical Prototype Networks - <i>P. Mettes, <b>E. van der Pol</b>, C.G.M. Snoek</i>, NeurIPS 2019 <br>
				&#183; <a href="https://papers.nips.cc/paper/8428-hyperspherical-prototype-networks">PDF</a> &#183; <a href="https://github.com/psmmettes/hpn">Code</a>
			</li>
		</ul>
		<h4>2018</h4>
		<ul>
			<li>
				Beyond Local Nash Equilibria for Adversarial Networks - <i>F.A. Oliehoek, R. Savani, J. Gallego-Posada, <b>E. van der Pol</b>, R. Gro&szlig;</i>, Benelearn 2018 <br>
				&#183; <a href="https://arxiv.org/abs/1806.07268">PDF</a>
			</li>
			<li>
				Visual Rationalizations in Deep Reinforcement Learning for Atari Games - <i>L. Weitkamp, <b>E. van der Pol</b>, Z. Akata</i>, BNAIC 2018 (Oral) <br>
				&#183; <a href="https://arxiv.org/abs/1902.00566">PDF</a>
			</li>
		</ul>
		<h4>2017</h4>
		<ul>
			<li>
				GANGs: Generative Adversarial Network Games - <i>F.A. Oliehoek, R. Savani, J. Gallego-Posada, <b>E. van der Pol</b>, E.D. de Jong, R. Gro&szlig;</i>, Arxiv Preprint <br>
				&#183; <a href="https://arxiv.org/abs/1712.00679">PDF</a>
		</ul>
		<h4>2016</h4>
		<ul>
			<li>
				Deep Reinforcement Learning for Coordination in Traffic Light Control - <i><b>E. van der Pol</b>, Master's Thesis</i>, University of Amsterdam <br>
				&#183; <a href="papers/vanderpolTHESIS2016.pdf">PDF</a>
			</li>
			<li>
				Coordinated Deep Reinforcement Learners for Traffic Light Control - <i><b>E. van der Pol</b>, F.A. Oliehoek</i>, NIPS 2016 Workshop on Learning, Inference and Control of Multi-Agent Systems <br>
				&#183; <a href="papers/vanderpolNIPSMALIC2016.pdf">PDF</a>
			</li>
			<li>
				Video Demo: Deep Reinforcement Learning for Coordination in Traffic Light Control - <i><b>E. van der Pol</b>, F.A. Oliehoek</i>, BNAIC 2016 <br>
				&#183; <a href="papers/vanderpolBNAIC2016b.pdf">PDF</a> &#183; <a href="https://www.fransoliehoek.net/trafficvideo">Video</a>
			</li>
			<li>
				Linguistic Style Accommodation in Disagreements - <i><b>E. van der Pol</b>, S. Gieske, R. Fern&aacute;ndez</i>, *SEM 2016 <br>
				&#183; <a href="papers/vanderpolStarSEM2016.pdf">PDF</a>
			</li>
		</ul>

		<h4>2015</h4>
		<ul>
			<li>
				Empirical Evaluation of Collective Rationality for Quota Rules in Judgment Aggregation - <i>S. Gieske, <b>E. van der Pol</b>, U. Endriss</i>, BNAIC 2015 <br>
				&#183; <a href="papers/gieskeBNAIC2015.pdf">PDF</a>
			</li>
		</ul>
	</div>


</body>

</html>
