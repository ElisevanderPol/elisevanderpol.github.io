<!doctype html>
<html lang="">

<head>
	<title>Elise van der Pol </title>
</head>

<!-- Style adapted from txti.es/ -->
<style type="text/css">body {font-size: 1.1em; line-height: 1.5em; max-width: 80em; margin: auto; padding: 0 2%;} img {max-width: 100%; display: block; margin: .75em auto;}</style>

<body>
	<div>
		<!--<img align="right" src="assets/twitter_foto.jpg" alt="Picture of Elise van der Pol in front of a whiteboard" width="256">-->
		<img align="right" src="assets/new_photo.jpg" alt="Picture of Elise van der Pol flexing a bicep" width="384">
		<h1>Elise van der Pol</h1>
		<h3>PhD student, University of Amsterdam</h3>
	</div>
	<div>
		<ul>
			<li>
				E-mail: e.e.vanderpol[at]uva[dot]nl
			</li>
			<li>
				<a href="https://twitter.com/ElisevanderPol">Twitter</a>
			</li>
			<li>
				<a href="https://scholar.google.nl/citations?hl=en&user=564o-vIAAAAJ">Google Scholar</a>
			</li>
		</ul>
	</div>

	<div>
		<p>My research interests lie in structure, symmetry, and equivariance in reinforcement learning and machine learning. I'm a PhD student in the <a href="https://amlab.science.uva.nl">Amsterdam Machine Learning Lab</a>, working with <a href="https://staff.fnwi.uva.nl/m.welling/">Max Welling</a> (UvA), <a href="https://www.fransoliehoek.net/">Frans Oliehoek</a> (TU Delft) and <a href="https://staff.fnwi.uva.nl/h.c.vanhoof/homepage/">Herke van Hoof</a> (UvA). Before my PhD, I studied Artificial Intelligence at the University of Amsterdam where I obtained my Master's degree (cum laude). My MSc thesis was on the subject of <a href="papers/vanderpolTHESIS2016.pdf">Deep Reinforcement Learning for Coordinated Traffic Light Controllers</a>. I am also involved in <a href="https://uva-iai.github.io/">Inclusive AI</a>.</p>
	</div>

	<div>
		<h2>News</h2>
		<h4>2021</h4>
		<ul>
			<li><u>Organization</u>: We're organizing an <a href="https://www.elisevanderpol.nl/badhypothesiscontest/">ICLR social</a> which takes place 6 May 2021.</li>
			<li><u>Talk</u>: 8 May 2021 I'm giving a talk on <b>Equivariance in MDPs</b> at the ICLR workshop on <a href="https://sslrlworkshop.github.io/">Self-supervision for Reinforcement Learning</a>.</li>
		</ul>
		<h4>2020</h4>
		<ul>
			<li><u>Talk</u>: 15 December 2020 I gave a talk on <b>MDP Homomorphic Networks for Deep Reinforcement Learning</b> at the University of Tuebingen.</li>
			<li><u>Talk</u>: 23 November 2020 I gave a guest lecture <b>Introduction to Reinforcement Learning</b> in University of Amsterdam's MSc Data Science course <i>Applied Machine Learning</i>.</li>
			<li><u>Talk</u>: 13 November 2020 I gave a talk on <b>Equivariance, deep reinforcement learning, and making it work</b> at Leiden University.</li> 
			<li><u>Talk</u>: I gave a talk on <b>Data-efficient Reinforcement Learning</b> as part of TU Delft's <i><a href="https://courses.edx.org/courses/course-v1:DelftX+AIIP1x+3T2020/course/">AI in Practice</a></i> course.
			<li><u>Paper</u>: <b>MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning</b> was accepted to NeurIPS 2020.</li>
			<li><u>Paper</u>: <b>Plannable Approximations to MDP Homomorphisms: Equivariance under Actions</b> was accepted to AAMAS 2020.</li>
			<li><u>Paper</u>: <b>Contrastive Learning of Structured World Models</b> was accepted to ICLR 2020 as a long talk.</li>
		</ul>
		<h4>2019</h4>
		<ul><li><u>Paper</u>: <b>Hyperspherical Prototype Networks</b> was accepted to NeurIPS 2019.</li></ul>
	</div>

	<div>
		<h2>Publications and Preprints</h2>
		<h4>2020</h4>
		<ul>
			<li>
				MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning - <i> <b>E. van der Pol</b>, D.E. Worrall, H. van Hoof, F.A. Oliehoek, M. Welling</i>, NeurIPS 2020 <br>
				&#183; <a href="https://proceedings.neurips.cc/paper/2020/file/2be5f9c2e3620eb73c2972d7552b6cb5-Paper.pdf">PDF</a> &#183; <a href="mhn.html">Overview</a> &#183; <a href="https://videos.neurips.cc/search/mdp%20homomorphic/video/slideslive-38936788">Video</a> &#183; <a href="https://github.com/ElisevanderPol/mdp-homomorphic-networks">Code</a> &#183; <a href="https://proceedings.neurips.cc/paper/2020/file/2be5f9c2e3620eb73c2972d7552b6cb5-Supplemental.pdf">Supplementary</a>
			<li>
				Plannable Approximations to MDP Homomorphisms: Equivariance under Actions - <i><b>E. van der Pol</b>, T. Kipf, F.A. Oliehoek, M. Welling</i>, AAMAS 2020  <br>
				&#183; <a href="https://arxiv.org/pdf/2002.11963.pdf">PDF</a> &#183; <a href="prae.html">Overview</a> &#183; <a href="https://underline.io/lecture/228-plannable-approximations-to-mdp-homomorphisms-equivariance-under-actions">Video</a> &#183; <a href="https://github.com/ElisevanderPol/PRAE">Code</a>
			</li>
			<li>
				Contrastive Learning of Structured World Models - <i>T. Kipf, <b>E. van der Pol</b>, M. Welling</i>, ICLR 2020 (Oral) <br>
				&#183; <a href="https://arxiv.org/abs/1911.12247">PDF</a> &#183; <a href="https://iclr.cc/virtual/poster_H1gax6VtDB.html">Video</a> &#183; <a href="https://github.com/tkipf/c-swm">Code</a>
			</li>
		</ul>
		<h4>2019</h4>
		<ul>
			<li>
				Hyperspherical Prototype Networks - <i>P. Mettes, <b>E. van der Pol</b>, C.G.M. Snoek</i>, NeurIPS 2019 <br>
				&#183; <a href="https://papers.nips.cc/paper/8428-hyperspherical-prototype-networks">PDF</a> &#183; <a href="https://github.com/psmmettes/hpn">Code</a>
			</li>
		</ul>
		<h4>2018</h4>
		<ul>
			<li>
				Beyond Local Nash Equilibria for Adversarial Networks - <i>F.A. Oliehoek, R. Savani, J. Gallego-Posada, <b>E. van der Pol</b>, R. Gro&szlig;</i>, Benelearn 2018 <br>
				&#183; <a href="https://arxiv.org/abs/1806.07268">PDF</a>
			</li>
			<li>
				Visual Rationalizations in Deep Reinforcement Learning for Atari Games - <i>L. Weitkamp, <b>E. van der Pol</b>, Z. Akata</i>, BNAIC 2018 (Oral) <br>
				&#183; <a href="https://arxiv.org/abs/1902.00566">PDF</a>
			</li>
		</ul>
		<h4>2017</h4>
		<ul>
			<li>
				GANGs: Generative Adversarial Network Games - <i>F.A. Oliehoek, R. Savani, J. Gallego-Posada, <b>E. van der Pol</b>, E.D. de Jong, R. Gro&szlig;</i>, Arxiv Preprint <br>
				&#183; <a href="https://arxiv.org/abs/1712.00679">PDF</a>
		</ul>
		<h4>2016</h4>
		<ul>
			<li>
				Deep Reinforcement Learning for Coordination in Traffic Light Control - <i><b>E. van der Pol</b>, Master's Thesis</i>, University of Amsterdam <br>
				&#183; <a href="papers/vanderpolTHESIS2016.pdf">PDF</a>
			</li>
			<li>
				Coordinated Deep Reinforcement Learners for Traffic Light Control - <i><b>E. van der Pol</b>, F.A. Oliehoek</i>, NIPS 2016 Workshop on Learning, Inference and Control of Multi-Agent Systems <br>
				&#183; <a href="papers/vanderpolNIPSMALIC2016.pdf">PDF</a>
			</li>
			<li>
				Video Demo: Deep Reinforcement Learning for Coordination in Traffic Light Control - <i><b>E. van der Pol</b>, F.A. Oliehoek</i>, BNAIC 2016 <br>
				&#183; <a href="papers/vanderpolBNAIC2016b.pdf">PDF</a> &#183; <a href="https://www.fransoliehoek.net/trafficvideo">Video</a>
			</li>
			<li>
				Linguistic Style Accommodation in Disagreements - <i><b>E. van der Pol</b>, S. Gieske, R. Fern&aacute;ndez</i>, *SEM 2016 <br>
				&#183; <a href="papers/vanderpolStarSEM2016.pdf">PDF</a>
			</li>
		</ul>

		<h4>2015</h4>
		<ul>
			<li>
				Empirical Evaluation of Collective Rationality for Quota Rules in Judgment Aggregation - <i>S. Gieske, <b>E. van der Pol</b>, U. Endriss</i>, BNAIC 2015 <br>
				&#183; <a href="papers/gieskeBNAIC2015.pdf">PDF</a>
			</li>
		</ul>
	</div>


</body>

</html>
